{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de69cdc1-399e-47e6-ae0c-b2fb7b80c78c",
   "metadata": {},
   "source": [
    "# Get Started With Reasoning Models\n",
    "\n",
    "This is your first introduction to working with reasoning models, code-first. In this notebook, we'll primarily use the o4-mini model. However, we will also explore the `o1` model briefly, to understand how the API works for both. Use [this table](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/reasoning?tabs=python-secure%2Cpy#api--feature-support) for the latest information on supported features. And visit the [Reasoning Models](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/reasoning?tabs=python%2Cpy) documentation page for API details and code snippets. Here's a quick summary for convenience:\n",
    "\n",
    "<br/>\n",
    "\n",
    "| Characteristic | o1 | o4-mini |\n",
    "|:--- |:---|:---|\n",
    "| Developer Messages    | ✅ | ✅ |\n",
    "| Structured Outputs    | ✅ | ✅ |\n",
    "| Context Window Input  | 200K | 100K |\n",
    "| Context Window Output | 200K | 100K |\n",
    "| Reasoning Effort      | ✅ | ✅ |\n",
    "| Vision Support        | ✅ | ✅ |\n",
    "| Chat Completions API  | ✅ | ✅ |\n",
    "| Responses API         | ✅ |    |\n",
    "| Functions / Tools     | ✅ | ✅ |\n",
    "| max_completion_tokens | ✅ |    |\n",
    "| System messages       | ✅ | ✅ |\n",
    "| Reasoning summary     | ✅ | |\n",
    "| Streaming             | ✅ | |\n",
    "| Model Card | [o4-mini](https://ai.azure.com/explore/models/o4-mini/version/2025-04-16/registry/azure-openai) | [o1](https://ai.azure.com/explore/models/o1/version/2024-12-17/registry/azure-openai)  |\n",
    "| api_version | 2025-04-01-preview | 2025-03-01-preview |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f57c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Quickstart\n",
    "\n",
    "In this section, we'll do a quick check to make sure we have the right dependencies installed. We'll also test both o1 and o4-mini models but we'll primarily use the `o4-mini` unless explicitly stated otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c08a8",
   "metadata": {},
   "source": [
    "### 1.1 Install Python Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install and Upgrade Pip\n",
    "# !pip install --upgrade pip --quiet\n",
    "\n",
    "# # Install Required Packages\n",
    "# !pip install -q openai azure-identity python-dotenv --quiet\n",
    "\n",
    "# # You may need to updated your OpenAI Python library\n",
    "# !pip install openai --upgrade --quiet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2aec38",
   "metadata": {},
   "source": [
    "### 1.2 Check Env Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "023c321d-b6af-42eb-b17b-1155e8cc4a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure OpenAI endpoint and key are set.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv(\"AZURE_OPENAI_ENDPOINT\"):\n",
    "    print(\"Missing env: AZURE_OPENAI_ENDPOINT\")\n",
    "elif not os.getenv(\"AZURE_OPENAI_API_KEY\"):\n",
    "    print(\"Missing env: AZURE_OPENAI_API_KEY\")\n",
    "else: \n",
    "    print(\"Azure OpenAI endpoint and key are set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e43dfb4",
   "metadata": {},
   "source": [
    "### 1.3 Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "020bab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats for the response\n",
    "def pretty_print(response, response_time):\n",
    "    \"\"\"\n",
    "    Prints the response details in a formatted manner.\n",
    "    Args:\n",
    "        response (openai.types.chat.chat_completion.ChatCompletion): The response object containing the generated completion.\n",
    "        response_time (float): The time taken to get the response.\n",
    "    \"\"\"\n",
    "    print(\".........................\")\n",
    "    print(f\"Response time: {response_time:.2f} seconds\")\n",
    "    print(f\"Total Tokens: {response.usage.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {response.usage.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {response.usage.completion_tokens}\")\n",
    "    print(f\"Reasoning Tokens: {response.usage.completion_tokens_details.reasoning_tokens}\")\n",
    "    print(f\"Output Tokens: {response.usage.total_tokens - response.usage.completion_tokens_details.reasoning_tokens}\")\n",
    "    print(f\"\\nResponse:\\n {response.choices[0].message.content}\")\n",
    "    print(f\".........................\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8017cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import AzureOpenAI\n",
    "import time\n",
    "\n",
    "# Chat with o1\n",
    "def o1_chat(prompt=\"hi\", reasoning_level=\"medium\", developer_message=\"You are a helpful assistant\"):\n",
    "    \"\"\"\n",
    "    Sends a chat completion request to the Azure OpenAI API o1 model.\n",
    "    Args:\n",
    "        prompt (str): The input prompt to generate a response for.\n",
    "        reasoning_level (str): The reasoning effort level ('low', 'medium', 'high').\n",
    "        developer_message (str): The developer message to set the context for the assistant.\n",
    "    Returns:\n",
    "        response (openai.types.chat.chat_completion.ChatCompletion): The response object containing the generated completion.\n",
    "    \"\"\"\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "        api_version=\"2025-04-01-preview\"\n",
    "    )\n",
    "    try:\n",
    "        request_time = time.time()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"o1\",\n",
    "            messages=[\n",
    "                {\"role\": \"developer\", \"content\": developer_message},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            max_completion_tokens=5000,\n",
    "            reasoning_effort=reasoning_level\n",
    "        )\n",
    "        response_time = time.time() - request_time\n",
    "        pretty_print(response, response_time)\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d15e040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with o4_mini\n",
    "def o4mini_chat(prompt=\"hi\", reasoning_level=\"medium\", developer_message=\"You are a helpful assistant\", response_format=None):\n",
    "    \"\"\"\n",
    "    Sends a chat completion request to the Azure OpenAI API o4-mini model.\n",
    "    Args:\n",
    "        prompt (str): The input prompt to generate a response for.\n",
    "        reasoning_level (str): The reasoning effort level ('low', 'medium', 'high').\n",
    "        developer_message (str): The developer message to set the context for the assistant.\n",
    "        response_format (BaseModel, optional): The expected structured output format for the response.\n",
    "    Returns:\n",
    "        response (openai.types.chat.chat_completion.ChatCompletion): The response object containing the generated completion.\n",
    "    \"\"\"\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "        api_version=\"2025-04-01-preview\"\n",
    "    )\n",
    "    try:\n",
    "        request_time = time.time()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"o4-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"developer\", \"content\": developer_message},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            max_completion_tokens=5000,\n",
    "            reasoning_effort=reasoning_level,\n",
    "            response_format=response_format\n",
    "        )\n",
    "        response_time = time.time() - request_time\n",
    "        pretty_print(response, response_time)\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e070d28",
   "metadata": {},
   "source": [
    "## 2.Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af7677c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\n",
      "Response time: 3.77 seconds\n",
      "Total Tokens: 258\n",
      "Prompt Tokens: 25\n",
      "Completion Tokens: 233\n",
      "Reasoning Tokens: 192\n",
      "Output Tokens: 66\n",
      "\n",
      "Response:\n",
      " There are three “p”s in the word “hippopotamus.”\n",
      ".........................\n"
     ]
    }
   ],
   "source": [
    "# Test o1\n",
    "response = o1_chat(\n",
    "    prompt=\"How many p's in hippopotamus?\",\n",
    "    reasoning_level=\"medium\",\n",
    "    developer_message=\"You are a helpful assistant.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d23f18a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\n",
      "Response time: 7.60 seconds\n",
      "Total Tokens: 188\n",
      "Prompt Tokens: 25\n",
      "Completion Tokens: 163\n",
      "Reasoning Tokens: 128\n",
      "Output Tokens: 60\n",
      "\n",
      "Response:\n",
      " The word “hippopotamus” contains 3 letter p’s.\n",
      ".........................\n"
     ]
    }
   ],
   "source": [
    "# Test o4mini\n",
    "response = o4mini_chat(\n",
    "    prompt=\"How many p's in hippopotamus?\",\n",
    "    reasoning_level=\"low\",\n",
    "    developer_message=\"You are a helpful assistant.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd3791",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Let's Prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5d7b58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\n",
      "Response time: 1.95 seconds\n",
      "Total Tokens: 255\n",
      "Prompt Tokens: 38\n",
      "Completion Tokens: 217\n",
      "Reasoning Tokens: 64\n",
      "Output Tokens: 191\n",
      "\n",
      "Response:\n",
      " To find the time t it takes to go 90 miles at 60 mph, use the relation  \n",
      "   time = distance ÷ speed.  \n",
      "\n",
      "Here, distance = 90 mi, speed = 60 mi/h, so  \n",
      "   t = 90 mi ÷ 60 mi/h = 1.5 h.  \n",
      "\n",
      "In hours and minutes, 1.5 h = 1 hour + 0.5 hour  \n",
      "0.5 hour = 0.5×60 min = 30 min.  \n",
      "\n",
      "Answer: It takes 1 hour 30 minutes.\n",
      ".........................\n",
      "To find the time t it takes to go 90 miles at 60 mph, use the relation  \n",
      "   time = distance ÷ speed.  \n",
      "\n",
      "Here, distance = 90 mi, speed = 60 mi/h, so  \n",
      "   t = 90 mi ÷ 60 mi/h = 1.5 h.  \n",
      "\n",
      "In hours and minutes, 1.5 h = 1 hour + 0.5 hour  \n",
      "0.5 hour = 0.5×60 min = 30 min.  \n",
      "\n",
      "Answer: It takes 1 hour 30 minutes.\n"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "# MATH EXAMPLE\n",
    "# -------------------\n",
    "response = o4mini_chat(\n",
    "    prompt=\"A train travels at 60 mph. How long does it take to travel 90 miles?\",\n",
    "    reasoning_level=\"low\",\n",
    "    developer_message=\"You are a math tutor. Explain the solution\"\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4e20849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\n",
      "Response time: 10.56 seconds\n",
      "Total Tokens: 239\n",
      "Prompt Tokens: 38\n",
      "Completion Tokens: 201\n",
      "Reasoning Tokens: 128\n",
      "Output Tokens: 111\n",
      "\n",
      "Response:\n",
      " Let Tom have T apples. Then Jane has 2T, and together  \n",
      "T + 2T = 18  \n",
      "3T = 18  \n",
      "T = 6  \n",
      "\n",
      "So Tom has 6 apples and Jane has 2·6 = 12 apples.\n",
      ".........................\n",
      "Let Tom have T apples. Then Jane has 2T, and together  \n",
      "T + 2T = 18  \n",
      "3T = 18  \n",
      "T = 6  \n",
      "\n",
      "So Tom has 6 apples and Jane has 2·6 = 12 apples.\n"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "#  MATH REASONING\n",
    "# -------------------\n",
    "prompt = \"Jane has twice as many apples as Tom. Together they have 18 apples. How many does each person have?\"\n",
    "response = o4mini_chat(prompt)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fb580ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\n",
      "Response time: 4.16 seconds\n",
      "Total Tokens: 652\n",
      "Prompt Tokens: 33\n",
      "Completion Tokens: 619\n",
      "Reasoning Tokens: 320\n",
      "Output Tokens: 332\n",
      "\n",
      "Response:\n",
      " Although both spoons settle at the same room temperature, your hand “feels” temperature by sensing heat flow. Metal and wood differ sharply in how quickly they conduct heat away from (or toward) your skin:\n",
      "\n",
      "1. Thermal conductivity  \n",
      "   – Metals (e.g. steel, silver) have thermal conductivities tens to hundreds of times higher than wood.  \n",
      "   – At the moment you touch the metal spoon, it draws heat from your warmer hand much faster than the wood does.\n",
      "\n",
      "2. Heat flux and sensation  \n",
      "   – Thermoreceptors in your skin respond to the rate of temperature change (how fast heat is lost), not just the absolute temperature difference.  \n",
      "   – A contact surface that pulls heat away more rapidly feels “colder,” even if its actual temperature is identical.\n",
      "\n",
      "3. Thermal effusivity  \n",
      "   – More generally, a material’s thermal effusivity (√[k·ρ·c], where k is conductivity, ρ density, c specific heat) governs how it exchanges heat with your skin.  \n",
      "   – Metals rank high in effusivity and therefore create a stronger cooling sensation on touch.\n",
      "\n",
      "In contrast, wood is a good thermal insulator with low conductivity and effusivity. It slows the flow of heat from your hand, so the wood spoon feels closer to your own body temperature and therefore noticeably “warmer” than the metal spoon.\n",
      ".........................\n",
      "Although both spoons settle at the same room temperature, your hand “feels” temperature by sensing heat flow. Metal and wood differ sharply in how quickly they conduct heat away from (or toward) your skin:\n",
      "\n",
      "1. Thermal conductivity  \n",
      "   – Metals (e.g. steel, silver) have thermal conductivities tens to hundreds of times higher than wood.  \n",
      "   – At the moment you touch the metal spoon, it draws heat from your warmer hand much faster than the wood does.\n",
      "\n",
      "2. Heat flux and sensation  \n",
      "   – Thermoreceptors in your skin respond to the rate of temperature change (how fast heat is lost), not just the absolute temperature difference.  \n",
      "   – A contact surface that pulls heat away more rapidly feels “colder,” even if its actual temperature is identical.\n",
      "\n",
      "3. Thermal effusivity  \n",
      "   – More generally, a material’s thermal effusivity (√[k·ρ·c], where k is conductivity, ρ density, c specific heat) governs how it exchanges heat with your skin.  \n",
      "   – Metals rank high in effusivity and therefore create a stronger cooling sensation on touch.\n",
      "\n",
      "In contrast, wood is a good thermal insulator with low conductivity and effusivity. It slows the flow of heat from your hand, so the wood spoon feels closer to your own body temperature and therefore noticeably “warmer” than the metal spoon.\n"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "#  SCIENCE REASONING\n",
    "# -------------------\n",
    "prompt = \"Why does a metal spoon feel colder than a wooden spoon when left in the same room?\"\n",
    "response = o4mini_chat(prompt)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6d52a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\n",
      "Response time: 47.22 seconds\n",
      "Total Tokens: 1542\n",
      "Prompt Tokens: 36\n",
      "Completion Tokens: 1506\n",
      "Reasoning Tokens: 640\n",
      "Output Tokens: 902\n",
      "\n",
      "Response:\n",
      " Here’s a 6-week, Monday–Friday (1 hr/day) plan to take you from zero to a simple Python project in about 30 hours total.\n",
      "\n",
      "Week 1 – Python Fundamentals  \n",
      " Mon  Setup & Hello World  \n",
      " • Install Python & an editor/IDE (e.g. VS Code, PyCharm)  \n",
      " • Run the REPL, write your first “Hello, world!” script  \n",
      " Tue  Variables & Data Types  \n",
      " • int, float, str, bool  \n",
      " • Assignment, basic arithmetic, type conversion  \n",
      " Wed  Strings  \n",
      " • Indexing, slicing, methods (len, .upper(), .split(), etc.)  \n",
      " • f-strings & .format()  \n",
      " Thu  Basic I/O & Comments  \n",
      " • input(), print(), formatting output  \n",
      " • Writing clear comments and docstrings  \n",
      " Fri  Mini Practice  \n",
      " • Write a script that asks for name/age and prints a greeting & birth year  \n",
      "\n",
      "Week 2 – Flow Control  \n",
      " Mon  Booleans & Comparisons  \n",
      " • ==, !=, >, <, >=, <=, and, or, not  \n",
      " Tue  Conditional Statements  \n",
      " • if, elif, else  \n",
      " • Nested and chained conditions  \n",
      " Wed  for-Loops  \n",
      " • range(), iterating lists/strings  \n",
      " • loop control: break, continue  \n",
      " Thu  while-Loops  \n",
      " • Loop condition, infinite loops, practical uses  \n",
      " Fri  List Comprehensions  \n",
      " • Basic and conditional comprehensions  \n",
      "\n",
      "Week 3 – Core Data Structures  \n",
      " Mon  Lists  \n",
      " • Creation, indexing, slicing, common methods (.append, .pop, .sort)  \n",
      " Tue  Tuples & Sets  \n",
      " • Tuple immutability, set uniqueness, basic set operations  \n",
      " Wed  Dictionaries  \n",
      " • key/value, .get(), .keys(), .items(), iteration  \n",
      " Thu  Nested Structures & Iteration  \n",
      " • Looping through dicts of lists, list of dicts, etc.  \n",
      " Fri  Practice Exercise  \n",
      " • E.g. build & query a simple “phonebook” dict  \n",
      "\n",
      "Week 4 – Modular Code & the Standard Library  \n",
      " Mon  Functions  \n",
      " • def, parameters, return, scope, docstrings  \n",
      " Tue  Advanced Functions  \n",
      " • *args, **kwargs, default parameters, lambda  \n",
      " Wed  Modules & Packages  \n",
      " • import, from … import, __name__ == \"__main__\"  \n",
      " Thu  Key Standard Modules  \n",
      " • os, sys, math, random, datetime  \n",
      " Fri  pip & Virtual Envs  \n",
      " • pip install, requirements.txt, venv basics  \n",
      "\n",
      "Week 5 – Files, Errors & OOP Basics  \n",
      " Mon  File I/O  \n",
      " • open(), read(), readline(), write(), with-statement  \n",
      " Tue  Exceptions  \n",
      " • try/except/else/finally, raising exceptions  \n",
      " Wed  Debugging  \n",
      " • print debugging, using pdb or your IDE’s debugger  \n",
      " Thu  Classes & Objects (Part 1)  \n",
      " • class, __init__, attributes, methods  \n",
      " Fri  Classes & Objects (Part 2)  \n",
      " • inheritance, super(), __str__/__repr__  \n",
      "\n",
      "Week 6 – Capstone Mini-Project & Review  \n",
      " Mon  Project Planning  \n",
      " • Choose a simple app (e.g. CLI todo list, calculator, CSV analyzer)  \n",
      " • Sketch features & data flow, write pseudocode  \n",
      " Tue  Project Setup  \n",
      " • Create project folder, virtual env, main.py, module stubs  \n",
      " Wed  Core Implementation  \n",
      " • Code main features (functions/classes, I/O)  \n",
      " Thu  Polishing  \n",
      " • Add error handling, logging/print statements, docstrings  \n",
      " Fri  Testing & Next Steps  \n",
      " • Test all functions, fix bugs, reflect on what to learn next (web, data, etc.)  \n",
      "\n",
      "Further Resources  \n",
      "• Official tutorial: docs.python.org/3/tutorial  \n",
      "• “Automate the Boring Stuff with Python” by Al Sweigart  \n",
      "• Practice sites: HackerRank, LeetCode (easy), Codecademy Python course  \n",
      "\n",
      "Good luck and happy coding!\n",
      ".........................\n",
      "Here’s a 6-week, Monday–Friday (1 hr/day) plan to take you from zero to a simple Python project in about 30 hours total.\n",
      "\n",
      "Week 1 – Python Fundamentals  \n",
      " Mon  Setup & Hello World  \n",
      " • Install Python & an editor/IDE (e.g. VS Code, PyCharm)  \n",
      " • Run the REPL, write your first “Hello, world!” script  \n",
      " Tue  Variables & Data Types  \n",
      " • int, float, str, bool  \n",
      " • Assignment, basic arithmetic, type conversion  \n",
      " Wed  Strings  \n",
      " • Indexing, slicing, methods (len, .upper(), .split(), etc.)  \n",
      " • f-strings & .format()  \n",
      " Thu  Basic I/O & Comments  \n",
      " • input(), print(), formatting output  \n",
      " • Writing clear comments and docstrings  \n",
      " Fri  Mini Practice  \n",
      " • Write a script that asks for name/age and prints a greeting & birth year  \n",
      "\n",
      "Week 2 – Flow Control  \n",
      " Mon  Booleans & Comparisons  \n",
      " • ==, !=, >, <, >=, <=, and, or, not  \n",
      " Tue  Conditional Statements  \n",
      " • if, elif, else  \n",
      " • Nested and chained conditions  \n",
      " Wed  for-Loops  \n",
      " • range(), iterating lists/strings  \n",
      " • loop control: break, continue  \n",
      " Thu  while-Loops  \n",
      " • Loop condition, infinite loops, practical uses  \n",
      " Fri  List Comprehensions  \n",
      " • Basic and conditional comprehensions  \n",
      "\n",
      "Week 3 – Core Data Structures  \n",
      " Mon  Lists  \n",
      " • Creation, indexing, slicing, common methods (.append, .pop, .sort)  \n",
      " Tue  Tuples & Sets  \n",
      " • Tuple immutability, set uniqueness, basic set operations  \n",
      " Wed  Dictionaries  \n",
      " • key/value, .get(), .keys(), .items(), iteration  \n",
      " Thu  Nested Structures & Iteration  \n",
      " • Looping through dicts of lists, list of dicts, etc.  \n",
      " Fri  Practice Exercise  \n",
      " • E.g. build & query a simple “phonebook” dict  \n",
      "\n",
      "Week 4 – Modular Code & the Standard Library  \n",
      " Mon  Functions  \n",
      " • def, parameters, return, scope, docstrings  \n",
      " Tue  Advanced Functions  \n",
      " • *args, **kwargs, default parameters, lambda  \n",
      " Wed  Modules & Packages  \n",
      " • import, from … import, __name__ == \"__main__\"  \n",
      " Thu  Key Standard Modules  \n",
      " • os, sys, math, random, datetime  \n",
      " Fri  pip & Virtual Envs  \n",
      " • pip install, requirements.txt, venv basics  \n",
      "\n",
      "Week 5 – Files, Errors & OOP Basics  \n",
      " Mon  File I/O  \n",
      " • open(), read(), readline(), write(), with-statement  \n",
      " Tue  Exceptions  \n",
      " • try/except/else/finally, raising exceptions  \n",
      " Wed  Debugging  \n",
      " • print debugging, using pdb or your IDE’s debugger  \n",
      " Thu  Classes & Objects (Part 1)  \n",
      " • class, __init__, attributes, methods  \n",
      " Fri  Classes & Objects (Part 2)  \n",
      " • inheritance, super(), __str__/__repr__  \n",
      "\n",
      "Week 6 – Capstone Mini-Project & Review  \n",
      " Mon  Project Planning  \n",
      " • Choose a simple app (e.g. CLI todo list, calculator, CSV analyzer)  \n",
      " • Sketch features & data flow, write pseudocode  \n",
      " Tue  Project Setup  \n",
      " • Create project folder, virtual env, main.py, module stubs  \n",
      " Wed  Core Implementation  \n",
      " • Code main features (functions/classes, I/O)  \n",
      " Thu  Polishing  \n",
      " • Add error handling, logging/print statements, docstrings  \n",
      " Fri  Testing & Next Steps  \n",
      " • Test all functions, fix bugs, reflect on what to learn next (web, data, etc.)  \n",
      "\n",
      "Further Resources  \n",
      "• Official tutorial: docs.python.org/3/tutorial  \n",
      "• “Automate the Boring Stuff with Python” by Al Sweigart  \n",
      "• Practice sites: HackerRank, LeetCode (easy), Codecademy Python course  \n",
      "\n",
      "Good luck and happy coding!\n"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "#  MULTI-STEP PLANNING\n",
    "# -------------------\n",
    "prompt = \"Design a basic weekly study schedule to learn Python in 6 weeks, assuming 1 hour per weekday.\"\n",
    "response = o4mini_chat(prompt)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cba29ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\n",
      "Response time: 5.80 seconds\n",
      "Total Tokens: 826\n",
      "Prompt Tokens: 59\n",
      "Completion Tokens: 767\n",
      "Reasoning Tokens: 640\n",
      "Output Tokens: 186\n",
      "\n",
      "Response:\n",
      " Here’s one way to do it using three back‐to‐back, non‐overlapping 4-hour shifts:\n",
      "\n",
      "• Alex:  8 AM – 12 PM  \n",
      "• Sam: 12 PM – 4 PM  \n",
      "• Riley: 4 PM – 8 PM  \n",
      "\n",
      "– Only Alex (8–12) and Riley (4–8) ever start before noon.  \n",
      "– Sam’s shift ends at 4 PM, so he never works past 4.\n",
      ".........................\n",
      "Here’s one way to do it using three back‐to‐back, non‐overlapping 4-hour shifts:\n",
      "\n",
      "• Alex:  8 AM – 12 PM  \n",
      "• Sam: 12 PM – 4 PM  \n",
      "• Riley: 4 PM – 8 PM  \n",
      "\n",
      "– Only Alex (8–12) and Riley (4–8) ever start before noon.  \n",
      "– Sam’s shift ends at 4 PM, so he never works past 4.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# CONSTRAINT-BASED SCHEDULING\n",
    "# --------------------------------\n",
    "prompt = \"Three employees—Alex, Sam, and Riley—must each work one 4-hour shift today. Only Alex and Riley can work before noon, and Sam can’t work past 4 PM. Create a valid schedule.\"\n",
    "response = o4mini_chat(prompt)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# TRY YOUR OWN\n",
    "# -------------------\n",
    "\n",
    "# Write your own prompt here\n",
    "prompt = \"\"  \n",
    "\n",
    "# Change these if you want to experiment\n",
    "reasoning_level = \"medium\"\n",
    "developer_message = \"You are a helpful assistant.\"\n",
    "response = o4mini_chat(prompt, reasoning_level, developer_message)\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
